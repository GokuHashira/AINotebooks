{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bq5yzUpBLdsL"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "cJDMbNyDLhmd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, d_model=2, row_dim=0, col_dim=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, token_encodings):\n",
        "\n",
        "    q = self.W_q(token_encodings)\n",
        "    k = self.W_k(token_encodings)\n",
        "    v = self.W_v(token_encodings)\n",
        "\n",
        "    sims = torch.matmul(q,k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "    scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "    attention_percent = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "    attention = torch.matmul(attention_percent, v)\n",
        "\n",
        "    return attention"
      ],
      "metadata": {
        "id": "eAu9pbz3LtGQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_matrix = torch.tensor([[1.16, 0.23],[0.57,1.36],[4.41,-2.16]])"
      ],
      "metadata": {
        "id": "BiU14ey0Lx_0"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msUXyqYXNbYO",
        "outputId": "c0df4b86-f104-4489-e390-707ac8f380b2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa54422cd30>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention = SelfAttention(d_model=2, row_dim=0, col_dim=1  )"
      ],
      "metadata": {
        "id": "24r56kV4Ns5T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention(encoding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnAmzgdoN45I",
        "outputId": "02d61a3d-61d5-4e29-f8d6-415cae363e22"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_q.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj0YHd78OAKO",
        "outputId": "cc5a0451-28b8-4a40-9e8f-2817782b1cba"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_k.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQcMe2I7OTpm",
        "outputId": "1f049e74-7895-48a4-9283-f807c64a8315"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_v.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZXMntILOa3k",
        "outputId": "666000e4-469f-4966-8059-8278e056d5a1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_q(encoding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5NUhYJnOb2d",
        "outputId": "01187ecb-bb0d-4b4c-8130-6cf52ce1118d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_k(encoding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECuKhzz2Og-z",
        "outputId": "ee72495d-ad15-4b99-e012-b5dd42592dc6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selfAttention.W_v(encoding_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_iQPvRbOobO",
        "outputId": "c80d5ffb-3e1a-4611-8f7a-1d8438e03b31"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = selfAttention.W_q(encoding_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8fcfrubOq_A",
        "outputId": "941fbf5b-e73a-46cc-ce31-b80b19441aea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = selfAttention.W_k(encoding_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVwdRlRzPCOe",
        "outputId": "0d1e89e5-288e-46c0-89e4-fe675b1ae9ff"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NFEP70QPDp5",
        "outputId": "d74d6ea9-3383-470b-be5f-393bcb154ca9"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0990,  0.0648, -0.6523],\n",
              "        [-0.4022,  0.4078, -3.0024],\n",
              "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_sims = sims / (torch.tensor(2)**0.5)\n",
        "scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHJsrWbMPFr9",
        "outputId": "0aa24a93-35a2-45df-afbe-24ad88dd055d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0700,  0.0458, -0.4612],\n",
              "        [-0.2844,  0.2883, -2.1230],\n",
              "        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_percents = F.softmax(scaled_sims, dim=1)\n",
        "attention_percents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsAxLJ_sPIjK",
        "outputId": "047322ce-b817-49be-cf24-0edfd8c14a38"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3573, 0.4011, 0.2416],\n",
              "        [0.3410, 0.6047, 0.0542],\n",
              "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attention_percents, selfAttention.W_v(encoding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecwV94CmPJ7v",
        "outputId": "1891ad67-034f-4ffc-939e-e1dafb6b66c4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Masked Attention"
      ],
      "metadata": {
        "id": "PB78vm-3PL2D"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "  def __init__(self, d_model=2, row_dim=0, col_dim=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias= False)\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, token_encodings, mask=None):\n",
        "\n",
        "    q = self.W_q(token_encodings)\n",
        "    k = self.W_k(token_encodings)\n",
        "    v = self.W_v(token_encodings)\n",
        "\n",
        "    sims = torch.matmul(q,k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "    scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "    if mask is not None:\n",
        "      scaled_sims = scaled_sims.masked_fill(mask=mask, value=float(\"-inf\"))\n",
        "    attention_percent = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "    attention = torch.matmul(attention_percent, v)\n",
        "\n",
        "    return attention"
      ],
      "metadata": {
        "id": "Atc8MZeFbtxQ"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoding_matrix = torch.tensor([[1.16, 0.23],[0.57,1.36],[4.41,-2.16]])\n",
        "torch.manual_seed(42)\n",
        "\n",
        "maskedSelfAttention = MaskedSelfAttention(d_model=2,\n",
        "                               row_dim=0,\n",
        "                               col_dim=1)\n",
        "\n",
        "mask = torch.tril(torch.ones(3, 3))\n",
        "mask = mask == 0\n",
        "mask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCq9CMr3dWhs",
        "outputId": "56ba6933-dc80-4202-87f0-3ad7a9bafe77"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskedSelfAttention(encoding_matrix, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I2QguGHdluH",
        "outputId": "4aa47d44-8a19-4560-80b3-4556a28f65b6"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.0062,  0.6072],\n",
              "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskedSelfAttention.W_q.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gomtRaE2dqd3",
        "outputId": "486e366e-60d3-483d-8f09-4cd7baa3f931"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskedSelfAttention.W_k.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRkg3O2fd3TI",
        "outputId": "a21c8af4-4a8a-4205-e9f3-51f0d6e693fc"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maskedSelfAttention.W_v.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxQb0Sl2d4cP",
        "outputId": "bcf2febd-1feb-43f3-b7cd-2130a78241d4"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = maskedSelfAttention.W_q(encoding_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OUKEJ-kd5U2",
        "outputId": "b2826f3b-ee80-487d-d6fa-6dfab7916364"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = maskedSelfAttention.W_k(encoding_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ME2zNJQneAoz",
        "outputId": "547c9d61-7492-4364-9743-045c7d7f9b4c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "v = maskedSelfAttention.W_v(encoding_matrix)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRfSsPJneCbZ",
        "outputId": "2b450fd1-1352-46de-af7d-9bb96151b367"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v-azOfKeDqJ",
        "outputId": "61d4b249-a2e3-42fe-b5dc-e9f066bb970d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0990,  0.0648, -0.6523],\n",
              "        [-0.4022,  0.4078, -3.0024],\n",
              "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_sims = sims / (torch.tensor(2)**0.5)"
      ],
      "metadata": {
        "id": "5Sf2NYR7eLu7"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "masked_scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "masked_scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LdMMcm-eNAf",
        "outputId": "ec848dd0-d9ae-43ec-dbaf-d9438590cd41"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.9975e-02, -1.0000e+09, -1.0000e+09],\n",
              "        [-2.8442e-01,  2.8833e-01, -1.0000e+09],\n",
              "        [ 3.4241e-01, -4.7253e-01,  2.8610e+00]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_percents = F.softmax(masked_scaled_sims, dim=1)\n",
        "attention_percents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nh4rV_geOsd",
        "outputId": "d22d3bb4-423d-4852-a2cb-7c31a0e429c2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.3606, 0.6394, 0.0000],\n",
              "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attention_percents, maskedSelfAttention.W_v(encoding_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2IjEFz5eQB3",
        "outputId": "a7c30b28-a19b-4725-f4e2-b8eac42dbcda"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.0062,  0.6072],\n",
              "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model=2,\n",
        "                 row_dim=0,\n",
        "                 col_dim=1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "        self.row_dim = row_dim\n",
        "        self.col_dim = col_dim\n",
        "\n",
        "    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n",
        "        q = self.W_q(encodings_for_q)\n",
        "        k = self.W_k(encodings_for_k)\n",
        "        v = self.W_v(encodings_for_v)\n",
        "\n",
        "        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n",
        "\n",
        "        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n",
        "\n",
        "        if mask is not None:\n",
        "            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "\n",
        "        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n",
        "\n",
        "        attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "        return attention_scores"
      ],
      "metadata": {
        "id": "zqzYi2GghodR"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encodings_for_q = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "encodings_for_k = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "encodings_for_v = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "## set the seed for the random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "## create an attention object\n",
        "attention = Attention(d_model=2,\n",
        "                      row_dim=0,\n",
        "                      col_dim=1)\n",
        "\n",
        "## calculate encoder-decoder attention\n",
        "attention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbsfVZnTeRAF",
        "outputId": "cb88180c-4925-42cf-d7be-b03454afbdc5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, d_model=2,\n",
        "                 row_dim=0,\n",
        "                 col_dim=1,\n",
        "               num_heads=1) -> None:\n",
        "     super().__init__()\n",
        "     self.heads = nn.ModuleList(\n",
        "         [Attention(d_model, row_dim, col_dim) for _ in range(num_heads)]\n",
        "     )\n",
        "     self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, encodings_for_q, encodings_for_k, encodings_for_v):\n",
        "      return torch.cat([head(encodings_for_q, encodings_for_k, encodings_for_v) for head in self.heads], dim=self.col_dim)"
      ],
      "metadata": {
        "id": "Uxe9rZnLhhxs"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## set the seed for the random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "## create an attention object\n",
        "multiHeadAttention = MultiHeadAttention(d_model=2,\n",
        "                                        row_dim=0,\n",
        "                                        col_dim=1,\n",
        "                                        num_heads=1)\n",
        "\n",
        "## calculate encoder-decoder attention\n",
        "multiHeadAttention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaNlQ1_ainb1",
        "outputId": "5dae5670-4638-41bd-8c25-c4ef77945641"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## set the seed for the random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "## create an attention object\n",
        "multiHeadAttention = MultiHeadAttention(d_model=2,\n",
        "                                        row_dim=0,\n",
        "                                        col_dim=1,\n",
        "                                        num_heads=2)\n",
        "\n",
        "## calculate encoder-decoder attention\n",
        "multiHeadAttention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhoyoU46iqhx",
        "outputId": "27646fb1-4374-4e2e-a57d-ccf58c30ba5a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0100,  1.0641, -0.7081, -0.8268],\n",
              "        [ 0.2040,  0.7057, -0.7417, -0.9193],\n",
              "        [ 3.4989,  2.2427, -0.7190, -0.8447]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5CO7Khq8ixBS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}